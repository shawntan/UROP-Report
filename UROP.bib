@article{Anton2004,
author = {Anton, Tobias},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.69.8848.pdf:pdf},
journal = {Lernen, Wissensentdeckung und Adaptivitt (LWA)},
number = {3},
title = {{XPath-Wrapper Induction by generalizing tree traversal patterns}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.8848\&amp;rep=rep1\&amp;type=pdf},
year = {2005}
}
@article{Arasu2003,
address = {New York, New York, USA},
annote = {ExAlg

        
No annotation

        
-Template inference
-Similar to roadrunner},
author = {Arasu, Arvind and Garcia-Molina, Hector},
doi = {10.1145/872757.872799},
file = {:home/shawn/Desktop/Dropbox/UROP/2003.10.1.1.93.6651.pdf:pdf},
isbn = {158113634X},
journal = {Proceedings of the 2003 ACM SIGMOD international conference on on Management of data - SIGMOD '03},
pages = {337},
publisher = {ACM Press},
title = {{Extracting structured data from Web pages}},
url = {http://portal.acm.org/citation.cfm?doid=872757.872799},
year = {2003}
}
@inproceedings{Arasu03,
abstract = {used to generate the pages (e.g., the author, title,...) typically come from a database. In this paper, we study the problem of automatically extracting the database values from such template-generated web pages without any learning examples or other similar human input. We formally define a template, and propose a model that describes how values are encoded into pages using a template. We present an algorithm that takes, as input, a set of template-generated pages, deduces the unknown template used to generate the pages, and extracts, as output, the values encoded in the pages. Experimental evaluation on a large number of real input page collections indicates that our algorithm correctly extracts data in most cases.},
author = {Arasu, Arvind and Garcia-Molina, Hector},
doi = {10.1145/872757.872799},
isbn = {158113634X},
pages = {337--348},
publisher = {ACM Press},
title = {{Extracting structured data from Web pages}},
type = {Conference proceedings (article)},
url = {http://infolab.stanford.edu/\~{}arvind/papers/extract-sigmod03.pdf  http://portal.acm.org/citation.cfm?id=872799},
year = {2003}
}
@article{Arlotta,
author = {Arlotta, Luigi and Crescenzi, Valter and Mecca, Giansalvatore and Merialdo, Paolo},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.11.1845.pdf:pdf},
title = {{Automatic Annotation of Data Extracted from Large Web Sites}}
}
@article{Arocena1999,
author = {Arocena, Gustavo O. and Mendelzon, Alberto O.},
doi = {10.1002/(SICI)1096-9942(1999)5:3<127::AID-TAPO2>3.0.CO;2-X},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.34.9263.pdf:pdf},
issn = {1074-3227},
journal = {Theory and Practice of Object Systems},
number = {3},
pages = {127--141},
title = {{WebOQL: Restructuring documents, databases, and webs}},
url = {http://doi.wiley.com/10.1002/\%28SICI\%291096-9942\%281999\%295\%3A3\%3C127\%3A\%3AAID-TAPO2\%3E3.0.CO\%3B2-X},
volume = {5},
year = {1999}
}
@article{B2005,
author = {B, Niko and K, Gabriella and Mandl, Stefan},
file = {:home/shawn/Downloads/10.1.1.68.9918.pdf:pdf},
journal = {Science},
title = {{An Evolutionary Approach to Tetris Basics and State of the Art Evolutionary optimizing Tetris}},
year = {2005}
}
@inbook{Badica06,
author = {Badica, Costin and Badica, Amelia and Popescu, Elvira},
doi = {10.1007/3-540-33880-2\_2},
editor = {Last, Mark and Szczepaniak, Piotr S. and Volkovich, Zeev and Kandel, Abraham},
isbn = {978-3-540-33879-6},
pages = {11--20},
publisher = {Springer},
series = {Studies in Computational Intelligence},
title = {{A New Path Generalization Algorithm for HTML Wrapper Induction}},
type = {Book part (with own title)},
url = {http://dblp.uni-trier.de/rec/bibtex/series/sci/BadicaBP06},
volume = {23},
year = {2006}
}
@article{Baumgartner2001,
author = {Baumgartner, Robert and Flesca, Sergio and Gottlob, Georg},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.76.6892.pdf:pdf},
journal = {Proceedings of the 27th VLDB Conference},
title = {{Visual Web Information Extraction with Lixto}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.76.6892\&amp;rep=rep1\&amp;type=pdf},
year = {2001}
}
@article{Bille2003,
author = {Bille, Philip},
file = {:home/shawn/Downloads/10.1.1.5.1567.pdf:pdf},
number = {March},
title = {{Tree Edit Distance , Alignment Distance and Inclusion}},
year = {2003}
}
@book{Bishop2007,
abstract = {\{The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.\}},
author = {Bishop, Christopher M.},
edition = {1st ed. 20},
isbn = {0387310738},
month = oct,
publisher = {Springer},
title = {{Pattern Recognition and Machine Learning (Information Science and Statistics)}},
type = {Book},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20\&amp;path=ASIN/0387310738 http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21\&amp;path=ASIN/0387310738 http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21\&amp;path=ASIN/0387310738 http://www.amazon.jp/exec/obidos/ASIN/0387310738 http://www.amazon.co.uk/exec/obidos/ASIN/0387310738/citeulike00-21 http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20\&path=ASIN/0387310738 http://www.worldcat.org/isbn/0387310738 htt},
year = {2007}
}
@article{Burges1998,
abstract = {The tutorial starts with an overview of the concepts of VC dimension
 and structural risk minimization. We then describe linear Support Vector 
 Machines (SVMs) for separable and non-separable data, working through a 
 non-trivial example in detail. We describe a mechanical analogy, and
 discuss when SVM solutions are unique and when they are global. We describe
 how support vector training can be practically implemented, and discuss in
 detail the kernel mapping technique which is used to construct SVM
 solutions which are nonlinear in the data. We show how Support Vector
 machines can have very large (even infinite) VC dimension by computing the
 VC dimension for homogeneous polynomial and Gaussian radial basis function
 kernels. While very high VC dimension would normally bode ill for
 generalization performance, and while at present there exists no theory
 which shows that good generalization performance is guaranteed for SVMs,
 there are several arguments which support the observed high accuracy of
 SVMs, which we review. Results of some experiments which were inspired by
 these arguments are also presented. We give numerous examples and proofs of
 most of the key theorems. There is new material, and I hope that the reader
 will find that even old material is cast in a fresh light.},
author = {Burges, Christopher J. C.},
doi = {10.1023/A:1009715923555},
issn = {1384-5810},
journal = {Data Min. Knowl. Discov.},
month = jun,
number = {2},
pages = {121--167},
publisher = {Kluwer Academic Publishers},
title = {{A Tutorial on Support Vector Machines for Pattern Recognition}},
type = {Journal article},
url = {http://portal.acm.org/citation.cfm?id=593463 http://www.springerlink.com/content/q87856173126771q},
volume = {2},
year = {1998}
}
@inproceedings{Cafarella2005,
abstract = {Numerous NLP applications rely on search-engine queries, both to extract information from and to compute statistics over the Web corpus. But search engines often limit the number of available queries. As a result, query-intensive NLP applications such as Information Extraction (IE) distribute their query load over several days, making IE a slow, offline process.This paper introduces a novel architecture for IE that obviates queries to commercial search engines. The architecture is embodied in a system called KnowItNow that performs high-precision IE in minutes instead of days. We compare KnowItNow experimentally with the previously-published KnowItAll system, and quantify the tradeoff between recall and speed. KnowItNow's extraction rate is two to three orders of magnitude higher than KnowItAll's.},
address = {Vancouver, British Columbia, Canada},
author = {Cafarella, Michael J. and Downey, Doug and Soderland, Stephen and Etzioni, Oren},
doi = {10.3115/1220575.1220646},
pages = {563--570},
publisher = {Association for Computational Linguistics},
title = {{KnowItNow: fast, scalable information extraction from the web}},
type = {Conference proceedings (article)},
url = {http://portal.acm.org/citation.cfm?id=1220646},
year = {2005}
}
@inproceedings{Califf1998,
abstract = {Information extraction systems process natural language documents and locate a specific set of relevant items. Given the recent success of empirical or corpus-based approaches in other areas of natural language processing, machine learning has the potential to significantly aid the development of these knowledge-intensive systems. This paper presents a system, RAPIER, that takes pairs of documents and filled templates and induces pattern-match rules that directly extract fillers for the slots...},
author = {Califf, M. E. and Mooney, R. J.},
pages = {6--11},
publisher = {AAAI Press},
title = {{Relational Learning of Pattern-Match Rules for Information Extraction}},
type = {Conference proceedings (article)},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.3310},
year = {1998}
}
@article{Carr2005,
author = {Carr, Donald},
file = {:home/shawn/Downloads/ApplyingReinforcementLearningToTetris\_DonaldCarr\_RU\_AC\_ZA.pdf:pdf},
journal = {Department of Computer Science, Rhodes University. Available at: http://colinfahey. com/tetris/ApplyingReinforcementLearningToTetris DonaldCarr RU AC ZA. pdf},
pages = {1--15},
title = {{Applying reinforcement learning to Tetris}},
url = {http://www.cs.ru.ac.za/research/g02C0108/files/litreviewfinalhandin.pdf},
year = {2005}
}
@misc{Chang,
abstract = {The research in information extraction (IE) regards the generation of wrappers that can extract particular information from semistructured Web documents. Similar to compiler generation, the extractor is actually a driver program, which is accompanied with the generated extraction rule. Previous work in this field aims to learn extraction rules from users' training example. In this paper, we propose IEPAD, a system that automatically discovers extraction rules from Web pages. The system can...},
author = {Chang, Chia Hui},
title = {{IEPAD: Information Extraction Based on Pattern Discovery}},
type = {Miscellaneous},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.9236}
}
@article{Chang2006,
abstract = {The Internet presents a huge amount of useful information which is usually formatted for its users, which makes it difficult to extract relevant data from various sources. Therefore, the availability of robust, flexible Information Extraction (IE) systems that transform the Web pages into program-friendly structures such as a relational database will become a great necessity. Although many approaches for data extraction from Web pages have been developed, there has been limited effort to compare such tools. Unfortunately, in only a few cases can the results generated by distinct tools be directly compared since the addressed extraction tasks are different. This paper surveys the major Web data extraction approaches and compares them in three dimensions: the task domain, the automation degree, and the techniques used. The criteria of the first dimension explain why an IE system fails to handle some Web sites of particular structures. The criteria of the second dimension classify IE systems based on the techniques used. The criteria of the third dimension measure the degree of automation for IE systems. We believe these criteria provide qualitatively measures to evaluate various IE approaches.},
author = {Chang, Chia Hui and Kayed, Mohammed and Girgis, Moheb Ramzy and Shaalan, Khaled F.},
doi = {10.1109/TKDE.2006.152},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.141.1628.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Trans. on Knowl. and Data Eng.},
month = oct,
number = {10},
pages = {1411--1428},
publisher = {IEEE Educational Activities Department},
title = {{A Survey of Web Information Extraction Systems}},
type = {Journal article},
url = {http://portal.acm.org/citation.cfm?id=1159162.1159300 http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1683775},
volume = {18},
year = {2006}
}
@article{Kayed2006,
author = {Chang, Chia-Hui and Kayed, Mohammed and Girgis, Moheb R. and Shaalan, Khaled F.},
doi = {10.1109/TKDE.2006.152},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.141.1628.pdf:pdf},
issn = {1041-4347},
journal = {IEEE Transactions on Knowledge and Data Engineering},
month = oct,
number = {10},
pages = {1411--1428},
title = {{A Survey of Web Information Extraction Systems}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1683775},
volume = {18},
year = {2006}
}
@article{Chang2001,
annote = {IEPAD
No annotation

        
-Assumes page has multiple entries in order to infer wrapper.},
author = {Chang, Chia-hui and Lui, Shao-Chen},
file = {:home/shawn/Desktop/Dropbox/UROP/2001.10.1.1.18.1532.pdf:pdf},
journal = {Proceedings of the 10th international conference on World Wide Web},
keywords = {extraction rule,information extraction,multiple string,pat tree},
pages = {681--688},
title = {{IEPAD : Information Extraction Based on Pattern Discovery}},
year = {2001}
}
@article{Chawathe1994,
author = {Chawathe, Sudarshan and Garcia-Molina, H and Hammer, Joachim and K},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.35.9238.pdf:pdf},
journal = {Proceedings of IPSJ},
pages = {1--12},
title = {{The TSIMMIS project: Integration of heterogeneous information sources}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.35.9238\&amp;rep=rep1\&amp;type=pdf},
year = {1994}
}
@article{Crescenzi2002,
annote = {RoadRunner

        
No annotation
-Template inference
-Compares 2 pages at a time},
arxivId = {10.1.1.21.8672},
author = {Crescenzi, Valter and Mecca, Giansalvatore and Merialdo, Paolo},
doi = {10.1.1.21.8672},
file = {:home/shawn/Desktop/Dropbox/UROP/2001.10.1.1.21.8672.pdf:pdf},
journal = {Proceedings of the 27th VLDB Conference},
title = {{RoadRunner : Towards Automatic Data Extraction from Large Web Sites}},
year = {2002}
}
@inproceedings{Crescenzi2001,
abstract = {The paper investigates techniques for extracting data from HTML sites through the use of automatically generated wrappers. To automate the wrapper generation and the data extraction process, the paper develops a novel technique to compare HTML pages and generate a wrapper based on their similarities and di\#erences. Experimental results on real-life data-intensive Web sites confirm the feasibility of the approach. 1},
author = {Crescenzi, Valter and Mecca, Giansalvatore and Merialdo, Paolo},
pages = {109--118},
title = {{RoadRunner: Towards Automatic Data Extraction from Large Web Sites}},
type = {Conference proceedings (article)},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.8672},
year = {2001}
}
@inproceedings{Cutler1999,
abstract = {Locating useful information effectively form the World Wide Web (WWW) is of wide interest. This paper presents new results on a methodology of using the structures and hyperlinks of HTML documents to improve the effectiveness of retrieving HTML documents. This methodology partitions the occurrences of terms in a document collection into classes according to the tags in which a particular term appears (such as Title, H1-H6, and Anchor). The rationale is that terms appearing in different structures of a document may have different significance in identifying the document. The weighting schemes of traditional information retrieval were extended to include class importance values. We implemented a genetic algorithm to determine a “best so far” class importance factor combination. Our experiments indicate that using this technique the retrieval effectiveness can be improved by 39.6\% or higher},
author = {Cutler, M. and Deng, H. and Maniccam, S.S. and Meng, W.},
booktitle = {Tools with Artificial Intelligence},
doi = {10.1109/TAI.1999.809831},
pages = {406--409},
title = {{A new study on using HTML structures to improve retrieval}},
type = {Conference proceedings (whole)},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=809831},
year = {1999}
}
@inproceedings{Dalvi2009,
author = {Dalvi, Nilesh and Bohannon, Philip and Sha, Fei},
booktitle = {Proceedings of the 35th SIGMOD international conference on Management of data},
file = {:home/shawn/Desktop/Dropbox/UROP/sigmod09.pdf:pdf},
pages = {335--348},
publisher = {ACM},
title = {{Robust web extraction: an approach based on a probabilistic tree-edit model}},
url = {http://portal.acm.org/citation.cfm?id=1559882},
year = {2009}
}
@inproceedings{Doorenbos1997,
address = {New York, New York, USA},
author = {Doorenbos, Robert B. and Etzioni, Oren and Weld, Daniel S.},
booktitle = {Proceedings of the first international conference on Autonomous agents - AGENTS '97},
doi = {10.1145/267658.267666},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.37.8120.pdf:pdf},
isbn = {0897918770},
pages = {39--48},
publisher = {ACM Press},
title = {{A scalable comparison-shopping agent for the World-Wide Web}},
url = {http://portal.acm.org/citation.cfm?doid=267658.267666},
year = {1997}
}
@article{Eikvil1999,
author = {Eikvil, Line},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.41.4905.pdf:pdf},
journal = {Norwegian Computing Center, PB},
number = {July},
publisher = {Citeseer},
title = {{Information extraction from world wide web-a survey}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.41.4905\&amp;rep=rep1\&amp;type=pdf},
volume = {114},
year = {1999}
}
@article{Etzioni2005,
annote = {KnowItAll

        
Unannotated data.

        
-Pattern learning
-Subclass extraction
-List extraction

      },
author = {Etzioni, O and Cafarella, M and Downey, D and Popescu, A and Shaked, T and Soderland, S and Weld, D and Yates, A},
doi = {10.1016/j.artint.2005.03.001},
file = {:home/shawn/Desktop/Dropbox/UROP/2004.10.1.1.124.8829.pdf:pdf},
issn = {00043702},
journal = {Artificial Intelligence},
month = jun,
number = {1},
pages = {91--134},
title = {{Unsupervised named-entity extraction from the Web: An experimental study}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0004370205000366},
volume = {165},
year = {2004}
}
@article{Etzioni2008,
annote = {TextRunner

        
Annotated examples

        
-single-pass extractor
-redundancy-based assesor},
author = {Etzioni, Oren and Banko, Michele and Soderland, Stephen and Weld, Daniel S.},
doi = {10.1145/1409360.1409378},
issn = {00010782},
journal = {Communications of the ACM},
keywords = {information extraction,knowledge acquisition,web mining},
month = dec,
number = {12},
pages = {68},
title = {{Open information extraction from the web}},
url = {http://portal.acm.org/citation.cfm?doid=1409360.1409378},
volume = {51},
year = {2008}
}
@article{Etzioni2004,
author = {Etzioni, Oren and Popescu, Ana-maria and Weld, Daniel S and Downey, Doug and Yates, Alexander},
file = {:home/shawn/Desktop/Dropbox/UROP/www-paper.pdf:pdf},
journal = {International World Wide Web Conference},
keywords = {information extraction,mutual information,search},
title = {{Web-Scale Information Extraction in KnowItAll ( Preliminary Results )}},
year = {2004}
}
@misc{Fahey,
author = {Fahey, Colin},
title = {{Tetris}},
url = {http://www.colinfahey.com/tetris/tetris\_en.html}
}
@article{Fleischer2008,
author = {Fleischer, Rudolf},
doi = {10.1007/s00224-008-9109-y},
file = {:home/shawn/Downloads/10.1.1.86.7871.pdf:pdf},
issn = {1432-4350},
journal = {Theory of Computing Systems},
month = mar,
number = {2},
pages = {205--214},
title = {{Die Another Day}},
url = {http://www.springerlink.com/index/10.1007/s00224-008-9109-y},
volume = {44},
year = {2008}
}
@article{Freitag1998,
annote = {SRV

        
Annotated examples

        
-Relational learning (Machine Learning)

        

        

        

      },
author = {Freitag, Dayne},
file = {:home/shawn/Desktop/Dropbox/UROP/1998.10.1.1.32.8501.pdf:pdf},
journal = {Search},
title = {{Information Extraction from HTML : Application of a General Machine Learning Approach Extraction as Text Classi cation}},
year = {1998}
}
@inproceedings{Gatterbauer2007,
abstract = {Traditionally, information extraction from web tables has focused on small, more or less homogeneous corpora, often based on assumptions about the use of},
address = {Banff, Alberta, Canada},
author = {Gatterbauer, Wolfgang and Bohunsky, Paul and Herzog, Marcus and Kr\"{u}pl, Bernhard and Pollak, Bernhard},
doi = {10.1145/1242572.1242583},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.69.5068.pdf:pdf},
isbn = {978-1-59593-654-7},
pages = {71--80},
publisher = {ACM},
title = {{Towards domain-independent information extraction from web tables}},
type = {Conference proceedings (article)},
url = {http://portal.acm.org/citation.cfm?id=1242583},
year = {2007}
}
@article{Gozali2007,
address = {New York, New York, USA},
author = {Gozali, Jesse Prabawa and Kan, Min-Yen},
doi = {10.1145/1255175.1255239},
file = {:home/shawn/Downloads/10.1.1.106.2440.pdf:pdf},
isbn = {9781595936448},
journal = {Proceedings of the 2007 conference on Digital libraries - JCDL '07},
keywords = {ajax,comp,edu,gui,human-computer interaction,kanmy,nus,opac,sg},
pages = {329},
publisher = {ACM Press},
title = {{A rich OPAC user interface with AJAX}},
url = {http://portal.acm.org/citation.cfm?doid=1255175.1255239},
year = {2007}
}
@misc{Guizhen,
abstract = {Template-driven HTML documents posses an implicit,
fixed schema denoting concepts and their relationships in
a hierarchical fashion. Discovering this schema remains a
relatively unexplored problem. By exploiting a key observation
that semantically related items in HTML documents
exhibit spatial locality, we develop an algorithm for automatically
partitioning them into tree-like semantic structures
which expose the implicit schema.},
author = {Guizhen, Saikat Mukherjee},
title = {{Automatic Discovery of Semantic Structures in HTML Documents}},
type = {Miscellaneous},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.1189}
}
@article{Gulhane2010,
address = {New York, New York, USA},
annote = {Small amount of annotated (seed) data

        
-Exploit content redundancy (duplicated content) within and across sites.},
author = {Gulhane, Pankaj and Rastogi, Rajeev and Sengamedu, Srinivasan H. and Tengli, Ashwin},
doi = {10.1145/1772690.1772826},
file = {:home/shawn/Desktop/Dropbox/UROP/2010.p1105-gulhane.pdf:pdf},
isbn = {9781605587998},
journal = {Proceedings of the 19th international conference on World wide web - WWW '10},
keywords = {content redundancy,information extraction},
number = {1},
pages = {1105},
publisher = {ACM Press},
title = {{Exploiting content redundancy for web information extraction}},
url = {http://portal.acm.org/citation.cfm?doid=1772690.1772826},
year = {2010}
}
@inproceedings{Gupta2003,
abstract = {Web pages often contain clutter (such as pop-up ads, unnecessary images and extraneous links) around the body of an article that distracts a user from actual content. Extraction of "useful and relevant" content from web pages has many applications, including cell phone and PDA browsing, speech rendering for the visually impaired, and text summarization. Most approaches to removing clutter or making content more readable involve changing font size or removing HTML and data components such as images, which takes away from a webpage's inherent look and feel. Unlike "Content Reformatting", which aims to reproduce the entire webpage in a more convenient form, our solution directly addresses "Content Extraction". We have developed a framework that employs easily extensible set of techniques that incorporate advantages of previous work on content extraction. Our key insight is to work with the DOM trees, rather than with raw HTML markup. We have implemented our approach in a publicly available Web proxy to extract content from HTML web pages.},
address = {Budapest, Hungary},
author = {Gupta, Suhit and Kaiser, Gail and Neistadt, David and Grimm, Peter},
doi = {10.1145/775152.775182},
isbn = {1-58113-680-3},
pages = {207--214},
publisher = {ACM},
title = {{DOM-based content extraction of HTML documents}},
type = {Conference proceedings (article)},
url = {http://portal.acm.org/citation.cfm?id=775152.775182},
year = {2003}
}
@article{Kl1995,
author = {Kl, Ontario},
file = {:home/shawn/Downloads/1995-372.pdf:pdf},
title = {{Tree-to-tree Correction for Document Trees Technical Report 95-372}},
year = {1995}
}
@inproceedings{Krupl2005,
abstract = {We describe a method to extract tabular data from web pages. Rather than just analyzing the DOM tree, we also exploit visual cues in the rendered version of the document to extract data from tables which are not explicitly marked with an HTML table element. To detect tables, we rely on a variant of the well-known X-Y cut algorithm as used in the OCR community. We implemented the system by directly accessing Mozilla's box model that contains the positional data for all HTML elements of a given web page.},
address = {Chiba, Japan},
author = {Kr\"{u}pl, Bernhard and Herzog, Marcus and Gatterbauer, Wolfgang},
doi = {10.1145/1062745.1062838},
isbn = {1-59593-051-5},
pages = {1000--1001},
publisher = {ACM},
title = {{Using visual cues for extraction of tabular data from arbitrary HTML documents}},
type = {Conference proceedings (article)},
url = {http://portal.acm.org/citation.cfm?id=1062745.1062838},
year = {2005}
}
@article{Kuhlins2002,
author = {Kuhlins, Stefan and Tredwell, Ross},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.19.6637.pdf:pdf},
journal = {World Wide Web Internet And Web Information Systems},
title = {{Toolkits for Generating Wrappers}},
year = {2002}
}
@misc{Kushmerick1997,
abstract = {The Internet presents numerous sources of useful information---telephone directories, product catalogs, stock quotes, weather forecasts, etc. Recently, many systems have been built that automatically gather and manipulate such information on a user's behalf. However, these resources are usually formatted for use by people (e.g., the relevant content is embedded in HTML pages), so extracting their content is difficult. Wrappers are often used for this purpose. A wrapper is a procedure for...},
annote = {WIEN

        
Annotated examples

        
-inductive learning of wrappers},
author = {Kushmerick, N. and Weld, D. and Doorenbos, R.},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.33.2176.pdf:pdf},
title = {{Wrapper induction for information extraction}},
type = {Miscellaneous},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.2176},
year = {1997}
}
@inbook{Kushmerick2003,
abstract = {For the purposes of this chapter, an information agent can be described as a distributed system that receives a goal through its user interface, gathers information relevant to this goal from a variety of sources, processes this content as appropriate, and delivers the results to the users. We focus on the second stage in this generic architecture. We survey a variety of information extraction techniques that enable information agents to automatically gather information from heterogeneous sources.},
author = {Kushmerick, Nicholas and Thomas, Bernd},
booktitle = {Intelligent Information Agents},
doi = {10.1007/3-540-36561-3\_4},
pages = {79--103},
title = {{Adaptive Information Extraction: Core Technologies for Information Agents}},
type = {Book part (with own title)},
year = {2003}
}
@article{Laender2002,
abstract = {In the last few years, several works in the literature have addressed the problem of data extraction from Web pages. The importance of this problem derives from the fact that, once extracted, the data can be handled in a way similar to instances of a traditional database. The approaches proposed in the literature to address the problem of Web data extraction use techniques borrowed from areas such as natural language processing, languages and grammars, machine learning, information retrieval, databases, and ontologies. As a consequence, they present very distinct features and capabilities which make a direct comparison difficult to be done. In this paper, we propose a taxonomy for characterizing Web data extraction fools, briefly survey major Web data extraction tools described in the literature, and provide a qualitative analysis of them. Hopefully, this work will stimulate other studies aimed at a more comprehensive analysis of data extraction approaches and tools for Web data.},
author = {Laender, Alberto H. F. and Neto, Berthier A. Ribeiro and da Silva, Altigran S. and Teixeira, Juliana S.},
doi = {10.1145/565117.565137},
issn = {0163-5808},
journal = {SIGMOD Rec.},
month = jun,
number = {2},
pages = {84--93},
publisher = {ACM},
title = {{A brief survey of web data extraction tools}},
type = {Journal article},
url = {http://portal.acm.org/citation.cfm?id=565137},
volume = {31},
year = {2002}
}
@article{Lagoudakis,
author = {Lagoudakis, Michail G and Parr, Ronald and Littman, Michael L},
file = {:home/shawn/Downloads/10.1.1.25.1818.pdf:pdf},
journal = {Policy},
title = {{Least-Squares Methods in Reinforcement Learning for Control}}
}
@article{AikMiang2005,
annote = {Parcels

        
-Zhng parcels by increasing classification accuracy through inter and intra similarity features},
author = {Lau, Aik Miang},
file = {::},
journal = {2004/2005 Honours Year Project Report, National University of Singapore},
title = {{Advancing PARCELS : PARser for Content Extraction and Logical Structure Using Inter- and Intra- Similarity Features Advancing PARCELS : PARser for Content Extraction and Logical Structure Using Inter- and Intra- Similarity Features}},
year = {2005}
}
@article{Lee2004,
address = {New York, New York, USA},
annote = {Parcels
        
Annotated examples
        
Cannot extract records from page, but takes into account stylistic and lexical attributes to classify "blocks" within a page.
        
-Machine learning
-Boosting},
author = {Lee, Chee How and Kan, Min-Yen and Lai, Sandra},
doi = {10.1145/1031453.1031478},
file = {:home/shawn/Desktop/Dropbox/UROP/p136-how.pdf:pdf},
isbn = {1581139780},
journal = {Proceedings of the 6th annual ACM international workshop on Web information and data management - WIDM '04},
keywords = {co-training,division,lexical and stylistic learners,parcels,web page,web page block classification},
pages = {136},
publisher = {ACM Press},
title = {{Stylistic and lexical co-training for web block classification}},
url = {http://portal.acm.org/citation.cfm?doid=1031453.1031478},
year = {2004}
}
@misc{Mukherjee2003,
abstract = {Template-driven HTML documents posses an implicit,
fixed schema denoting concepts and their relationships in
a hierarchical fashion. Discovering this schema remains a
relatively unexplored problem. By exploiting a key observation
that semantically related items in HTML documents
exhibit spatial locality, we develop an algorithm for automatically
partitioning them into tree-like semantic structures
which expose the implicit schema.},
author = {Mukherjee, S. and Yang, G. and Tan, W. and Ramakrishnan, I.},
title = {{Automatic Discovery of Semantic Structures in HTML documents}},
type = {Miscellaneous},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.4.1189},
year = {2003}
}
@inproceedings{Perkowitz1995,
author = {Perkowitz, M. and Etzioni, Oren},
booktitle = {International Joint Conference on Artificial Intelligence},
file = {:home/shawn/Desktop/Dropbox/UROP/10.1.1.154.5622.pdf:pdf},
pages = {930--938},
publisher = {Citeseer},
title = {{Category translation: Learning to understand information on the internet}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.154.5622\&amp;rep=rep1\&amp;type=pdf},
volume = {14},
year = {1995}
}
@article{Qi2009,
abstract = {Classification of Web page content is essential to many tasks in Web information retrieval such as maintaining Web directories and focused crawling. The uncontrolled nature of Web content presents additional challenges to Web page classification as compared to traditional text classification, but the interconnected nature of hypertext also provides features that can assist the process.},
author = {Qi, Xiaoguang and Davison, Brian D.},
doi = {10.1145/1459352.1459357},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
number = {2},
pages = {1--31},
publisher = {ACM},
title = {{Web page classification: Features and algorithms}},
type = {Journal article},
url = {http://portal.acm.org/citation.cfm?id=1459352.1459357},
volume = {41},
year = {2009}
}
@article{Raeymaekers2008,
annote = {Annotated examples.
        
-(k,l)-contextual tree},
author = {Raeymaekers, Stefan and Bruynooghe, Maurice and Bussche, Jan},
doi = {10.1007/s10994-008-5049-7},
file = {:home/shawn/Desktop/Dropbox/UROP/2008.10.1.1.151.2713.pdf:pdf},
issn = {0885-6125},
journal = {Machine Learning},
keywords = {information extraction,tree languages,wrapper induction},
month = mar,
number = {2-3},
pages = {155--183},
title = {{Learning (k,l)-contextual tree languages for information extraction from web pages}},
url = {http://www.springerlink.com/index/10.1007/s10994-008-5049-7},
volume = {71},
year = {2008}
}
@misc{Reis2004,
abstract = {The Web poses itself as the largest data repository ever available in
the history of humankind. Major efforts have been made in order
to provide efficient access to relevant information within this huge
repository of data. Although several techniques have been developed
to the problem of Web data extraction, their use is still not
spread, mostly because of the need for high human intervention and
the low quality of the extraction results. In this paper, we present
a domain-oriented approach to...},
author = {Reis, D. and Golgher, P. and Silva, A. and Laender, A.},
title = {{Automatic web news extraction using tree edit distance}},
type = {Miscellaneous},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.1.7765},
year = {2004}
}
@article{Sarjant2008,
author = {Sarjant, Sam},
file = {:home/shawn/Downloads/project-proposal (1).pdf:pdf},
journal = {Hand, The},
number = {March},
pages = {1--8},
title = {{Designing an AI Agent for playing Tetris using Reinforcement Learning}},
year = {2008}
}
@article{Schapire2000,
abstract = {This work focuses on algorithms which learn from examples to perform multiclass text and speech categorization tasks. Our approach is based on a new and improved family of boosting algorithms. We describe in detail an implementation, called BoosTexter, of the new boosting algorithms for text categorization tasks. We present results comparing the performance of BoosTexter and a number of other text-categorization algorithms on a variety of tasks. We conclude by describing the application of our system to automatic call-type identification from unconstrained spoken customer responses.},
author = {Schapire, Robert E. and Singer, Yoram},
doi = {10.1023/A:1007649029923},
journal = {Machine Learning},
month = may,
number = {2},
pages = {135--168},
title = {{Boos\{T\}exter: A Boosting-based System for Text Categorization}},
type = {Journal article},
volume = {39},
year = {2000}
}
@inproceedings{Shevade2005,
abstract = {This paper describes our system that enables members of a social network to collaboratively annotate a shared media collection. The problem is important since online social networks are emerging as conduits for exchange of everyday experiences. Our collaborative annotation system provides personalized recommendations to each user, based on (a) media features, (b) context, (c) commonsensical relationships and (d) linguistic relationships. We also develop novel concept specificity and abstractness/concreteness measures that further adapt the recommendations to the specific concept. Our preliminary user studies indicate that the system performs well and is more useful as compared to standard web browser recommendation schemes.},
author = {Shevade, B. and Sundaram, H. and Yen-Kan, Min},
booktitle = {Multimedia and Expo, 2005. ICME 2005. IEEE International Conference on},
pages = {1346--1349},
title = {{A Collaborative Annotation Framework}},
type = {Conference proceedings (whole)},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1521679},
year = {2005}
}
@article{Soderland,
annote = {WHISK

        
User annotation.
User defined lists.

        
-Semi-structured and free text},
author = {Soderland, Stephen},
file = {:home/shawn/Desktop/Dropbox/UROP/1999.10.1.1.41.8809.pdf:pdf},
journal = {World Wide Web Internet And Web Information Systems},
keywords = {1,an information,as more and more,automatically from text data,information extraction,natural language processing,need for,rule learning,systems that extract information,text becomes available on-line,there is a growing},
pages = {1--44},
title = {{Learning Information Extraction Rules for Semi-structured and Free Text}},
volume = {44},
year = {1999}
}
@misc{Soderland1997,
author = {Soderland, Stephen},
file = {:home/shawn/Desktop/Dropbox/UROP/KDD97-052.pdf:pdf},
title = {{Learning Information to Extract Text-based from the World Wide Web}},
year = {1997}
}
@article{Supervised,
author = {Supervised, Introduction and Unsupervised, I E and Other, I E},
file = {:home/shawn/Desktop/Dropbox/UROP/litreview.pdf:pdf},
title = {{Literature Review}}
}
@article{Tan1990,
author = {Tan, Shawn},
file = {::},
pages = {1--10},
title = {{UROP Literature Review Web Information Extraction}},
year = {1990}
}
@article{Tan1990a,
author = {Tan, Shawn},
file = {::},
pages = {1--10},
title = {{UROP Literature Review Web Information Extraction}},
year = {1990}
}
@article{Tan1990b,
author = {Tan, Shawn},
file = {::},
journal = {Information Systems},
pages = {1--5},
title = {{UROP Progress Report : User-centric Webpage Information Extraction}},
year = {1990}
}
@article{Tan1990c,
author = {Tan, Shawn},
file = {:home/shawn/Desktop/Dropbox/UROP/LitReview\_U096883L.pdf:pdf},
journal = {World Wide Web Internet And Web Information Systems},
pages = {1--10},
title = {{UROP Literature Review Web Information Extraction}},
year = {1990}
}
@article{Tan,
author = {Tan, Shawn},
file = {::},
pages = {1--10},
title = {{UROP Progress Report : User-centric Webpage Information Extraction}}
}
@article{Tan1990d,
author = {Tan, Shawn},
file = {:home/shawn/Desktop/Dropbox/UROP/litreview.pdf:pdf},
pages = {1--10},
title = {{UROP Literature Review Web Information Extraction}},
year = {1990}
}
@article{Turmo2006,
abstract = {The growing availability of online textual sources and the potential number of applications of knowledge acquisition from textual data has lead to an increase in Information Extraction (IE) research. Some examples of these applications are the generation of data bases from documents, as well as the acquisition of knowledge useful for emerging technologies like question answering, information integration, and others related to text mining. However, one of the main drawbacks of the application of IE refers to its intrinsic domain dependence. For the sake of reducing the high cost of manually adapting IE applications to new domains, experiments with different Machine Learning (ML) techniques have been carried out by the research community. This survey describes and compares the main approaches to IE and the different ML techniques used to achieve Adaptive IE technology.},
author = {Turmo, Jordi and Ageno, Alicia and Catal\&$\backslash$\#224;, Neus},
doi = {10.1145/1132956.1132957},
issn = {0360-0300},
journal = {ACM Comput. Surv.},
number = {2},
publisher = {ACM},
title = {{Adaptive information extraction}},
type = {Journal article},
url = {http://portal.acm.org/citation.cfm?id=1132957},
volume = {38},
year = {2006}
}
@article{Zhai2007,
abstract = {Abstract\&nbsp;\&nbsp;This paper studies structured data extraction from Web pages. Existing approaches to data extraction include wrapper induction and automated methods. In this paper, we propose an instance-based learning method, which performs extraction by comparing each new instance to be extracted with labeled instances. The key advantage of our method is that it does not require an initial set of labeled pages to learn extraction rules as in wrapper induction. Instead, the algorithm is able to start extraction from a single labeled instance. Only when a new instance cannot be extracted does it need labeling. This avoids unnecessary page labeling, which solves a major problem with inductive learning (or wrapper induction), i.e., the set of labeled instances may not be representative of all other instances. The instance-based approach is very natural because structured data on the Web usually follow some fixed templates. Pages of the same template usually can be extracted based on a single page instance of the template. A novel technique is proposed to match a new instance with a manually labeled instance and in the process to extract the required data items from the new instance. The technique is also very efficient. Experimental results based on 1,200 pages from 24 diverse Web sites demonstrate the effectiveness of the method. It also outperforms the state-of-the-art existing systems significantly.},
author = {Zhai, Yanhong and Liu, Bing},
doi = {10.1007/s11280-007-0022-0},
issn = {1386-145X},
journal = {World Wide Web},
month = jun,
number = {2},
pages = {113--132},
publisher = {Springer},
title = {{Extracting Web Data Using Instance-Based Learning}},
type = {Journal article},
url = {http://portal.acm.org/citation.cfm?id=1265174 http://www.ingentaconnect.com/content/klu/wwwj/2007/00000010/00000002/00000022 http://www.springerlink.com/content/39585174t3786x06},
volume = {10},
year = {2007}
}
@article{Zhai2006,
abstract = {This paper studies the problem of structured data extraction from arbitrary Web pages. The objective of the proposed research is to automatically segment data records in a page, extract data items/fields from these records, and store the extracted data in a database. Existing methods addressing the problem can be classified into three categories. Methods in the first category provide some languages to facilitate the construction of data extraction systems. Methods in the second category use machine learning techniques to learn wrappers (which are data extraction programs) from human labeled examples. Manual labeling is time-consuming and is hard to scale to a large number of sites on the Web. Methods in the third category are based on the idea of automatic pattern discovery. However, multiple pages that conform to a common schema are usually needed as the input. In this paper, we propose a novel and effective technique (called DEPTA) to perform the task of Web data extraction automatically. The method consists of two steps: 1) identifying individual records in a page and 2) aligning and extracting data items from the identified records. For step 1, a method based on visual information and tree matching is used to segment data records. For step 2, a novel partial alignment technique is proposed. This method aligns only those data items in a pair of records that can be aligned with certainty, making no commitment on the rest of the items. Experimental results obtained using a large number of Web pages from diverse domains show that the proposed two-step technique is highly effective},
author = {Zhai, Yanhong and Liu, Bing},
doi = {10.1109/TKDE.2006.197},
journal = {Knowledge and Data Engineering, IEEE Transactions on},
number = {12},
pages = {1614--1628},
title = {{Structured Data Extraction from the Web Based on Partial Tree Alignment}},
type = {Journal article},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1717419},
volume = {18},
year = {2006}
}
@article{Zhang1989,
author = {Zhang, Kaizhong and Shasha, Dennis},
file = {:home/shawn/Downloads/simple\_fast\_algorithms\_for\_the\_editing\_distance\_between\_tree\_and\_related\_problems.pdf:pdf},
issn = {0097-5397},
journal = {SIAM J. Comput.},
keywords = {68p05,68q20,68q25,68r10,ams,dynamic programming,editing distance,mos,parallel algorithm,pattern recognition,subject classifications,trees},
number = {6},
pages = {1245--1262},
title = {{Simple fast algorithms for the editing distance between trees and related problems}},
url = {http://www.grantjenks.com/wiki/\_media/ideas:simple\_fast\_algorithms\_for\_the\_editing\_distance\_between\_tree\_and\_related\_problems.pdf},
volume = {18},
year = {1989}
}
@misc{htmlunit,
title = {{HtmlUnit - Welcome to HtmlUnit, http://htmlunit.sourceforge.net/}},
url = {http://htmlunit.sourceforge.net/}
}
@misc{,
file = {:home/shawn/Desktop/Dropbox/UROP/litreview.pdf:pdf},
title = {litreview.pdf}
}
@misc{,
file = {:home/shawn/Desktop/Dropbox/UROP/litreview.pdf:pdf},
title = {litreview.pdf}
}
@article{,
file = {::},
pages = {1--5},
title = {{1 Method}}
}
@article{Needleman1970,
author = {Needleman, S.B. and Wunsch, C.D.},
file = {:home/shawn/Desktop/Dropbox/UROP/6.pdf:pdf},
issn = {0022-2836},
journal = {Journal of molecular biology},
number = {3},
pages = {443--453},
publisher = {Elsevier},
title = {{A general method applicable to the search for similarities in the amino acid sequence of two proteins}},
url = {http://linkinghub.elsevier.com/retrieve/pii/0022283670900574},
volume = {48},
year = {1970}
}
